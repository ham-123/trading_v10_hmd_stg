"""
Module d'intelligence artificielle pour le Trading Bot Volatility 10
Centralise les mod√®les LSTM, l'entra√Ænement et les pr√©dictions

Usage:
    from ai_model import train_model, predict_price, get_model_performance
    from ai_model import LSTMModel, ModelTrainer, ModelPredictor
    from ai_model import ModelConfig, TrainingConfig, PredictionConfig
"""

# Imports des classes principales
from .lstm_model import (
    LSTMModel,
    ModelConfig,
    ModelMetrics,
    ModelArchitecture,
    PredictionType,
    AttentionLayer,
    lstm_model
)

from .trainer import (
    ModelTrainer,
    TrainingConfig,
    TrainingResults,
    model_trainer,
    train_lstm_model
)

from .predictor import (
    ModelPredictor,
    PredictionConfig,
    PredictionResult,
    model_predictor,
    predict_price,
    get_prediction_stats
)

import logging
import os
import json
import numpy as np
import pandas as pd
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
import warnings

from config import config
from data import prepare_training_data

# Configuration du logger
logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore')

# Version du module
__version__ = "1.0.0"

# Informations sur le module
__author__ = "Trading Bot Team"
__description__ = "Module d'intelligence artificielle LSTM pour le Trading Bot Volatility 10"

# Exports principaux
__all__ = [
    # Classes LSTM
    "LSTMModel",
    "ModelConfig",
    "ModelMetrics",
    "ModelArchitecture",
    "PredictionType",
    "AttentionLayer",

    # Classes d'entra√Ænement
    "ModelTrainer",
    "TrainingConfig",
    "TrainingResults",

    # Classes de pr√©diction
    "ModelPredictor",
    "PredictionConfig",
    "PredictionResult",

    # Instances globales
    "lstm_model",
    "model_trainer",
    "model_predictor",

    # Fonctions utilitaires - Entra√Ænement
    "train_lstm_model",
    "train_and_evaluate_model",
    "optimize_hyperparameters",

    # Fonctions utilitaires - Pr√©diction
    "predict_price",
    "predict_direction",
    "batch_predict",
    "get_prediction_stats",

    # Fonctions du module
    "get_model_performance",
    "get_ai_pipeline_status",
    "auto_retrain_model",
    "load_best_model",
    "get_ai_insights",
    "validate_model_performance",

    # M√©tadonn√©es
    "__version__",
    "__author__",
    "__description__"
]


@dataclass
class ModelPerformance:
    """Performance globale des mod√®les IA"""
    # M√©triques principales
    accuracy: float = 0.0
    directional_accuracy: float = 0.0
    mae: float = 0.0
    sharpe_ratio: float = 0.0

    # Fiabilit√©
    prediction_consistency: float = 0.0
    confidence_calibration: float = 0.0
    model_stability: float = 0.0

    # Historique
    total_predictions: int = 0
    successful_predictions: int = 0
    last_evaluation: Optional[datetime] = None

    # Comparaison
    benchmark_accuracy: float = 0.5  # Pr√©cision al√©atoire
    performance_vs_benchmark: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class AIInsights:
    """Insights g√©n√©r√©s par l'IA"""
    # Pr√©dictions de march√©
    market_direction_confidence: float = 0.0
    volatility_forecast: str = "NORMAL"  # LOW, NORMAL, HIGH
    trend_strength: float = 0.0

    # Patterns d√©tect√©s
    recurring_patterns: List[str] = None
    anomaly_detection: List[str] = None
    support_resistance_ai: List[float] = None

    # Recommandations
    trading_recommendation: str = "HOLD"  # BUY, SELL, HOLD
    optimal_timeframe: str = "1m"
    risk_assessment: str = "MEDIUM"  # LOW, MEDIUM, HIGH

    # M√©tadonn√©es
    analysis_timestamp: datetime = None
    model_versions_used: List[str] = None
    data_quality_score: float = 0.0

    def __post_init__(self):
        if self.recurring_patterns is None:
            self.recurring_patterns = []
        if self.anomaly_detection is None:
            self.anomaly_detection = []
        if self.support_resistance_ai is None:
            self.support_resistance_ai = []
        if self.model_versions_used is None:
            self.model_versions_used = []
        if self.analysis_timestamp is None:
            self.analysis_timestamp = datetime.now(timezone.utc)


def train_and_evaluate_model(model_config: ModelConfig = None,
                             training_config: TrainingConfig = None,
                             symbol: str = "R_10") -> Dict[str, Any]:
    """
    Entra√Æne et √©value un mod√®le LSTM complet

    Args:
        model_config: Configuration du mod√®le
        training_config: Configuration de l'entra√Ænement  
        symbol: Symbole √† entra√Æner

    Returns:
        R√©sultats complets d'entra√Ænement et d'√©valuation
    """
    try:
        logger.info(f"üöÄ Entra√Ænement et √©valuation compl√®te pour {symbol}")

        # Configuration par d√©faut
        if model_config is None:
            model_config = ModelConfig()
        if training_config is None:
            training_config = TrainingConfig(symbol=symbol)

        # Cr√©er l'entra√Æneur
        trainer = ModelTrainer(training_config)

        # Entra√Ænement
        training_results = trainer.train_model(model_config)

        # Validation crois√©e
        cv_results = trainer.cross_validate(model_config, n_splits=3)

        # √âvaluation finale
        model_performance = evaluate_model_performance(trainer.model)

        # Compilation des r√©sultats
        complete_results = {
            'training_results': training_results.to_dict(),
            'cross_validation': cv_results,
            'model_performance': model_performance.to_dict(),
            'model_config': asdict(model_config),
            'training_config': asdict(training_config),
            'evaluation_timestamp': datetime.now(timezone.utc).isoformat()
        }

        logger.info(f"‚úÖ Entra√Ænement termin√© - Pr√©cision: {model_performance.accuracy:.3f}")
        return complete_results

    except Exception as e:
        logger.error(f"Erreur entra√Ænement et √©valuation: {e}")
        return {
            'error': str(e),
            'success': False,
            'timestamp': datetime.now(timezone.utc).isoformat()
        }


def evaluate_model_performance(model: LSTMModel) -> ModelPerformance:
    """
    √âvalue la performance d'un mod√®le entra√Æn√©

    Args:
        model: Mod√®le LSTM √† √©valuer

    Returns:
        M√©triques de performance
    """
    try:
        performance = ModelPerformance()

        if model is None or model.model is None:
            logger.warning("Aucun mod√®le √† √©valuer")
            return performance

        # R√©cup√©rer les m√©triques du mod√®le
        if hasattr(model, 'metrics'):
            metrics = model.metrics
            performance.accuracy = metrics.accuracy
            performance.directional_accuracy = metrics.directional_accuracy
            performance.mae = metrics.mae
            performance.sharpe_ratio = metrics.sharpe_ratio

        # Calculer les m√©triques suppl√©mentaires
        performance.last_evaluation = datetime.now(timezone.utc)

        # Performance vs benchmark
        performance.performance_vs_benchmark = performance.accuracy - performance.benchmark_accuracy

        # √âvaluation qualitative
        if performance.accuracy > 0.7:
            performance.model_stability = 0.9
        elif performance.accuracy > 0.6:
            performance.model_stability = 0.7
        else:
            performance.model_stability = 0.5

        logger.debug(f"Performance √©valu√©e: accuracy={performance.accuracy:.3f}")
        return performance

    except Exception as e:
        logger.error(f"Erreur √©valuation performance: {e}")
        return ModelPerformance()


def optimize_hyperparameters(symbol: str = "R_10",
                             max_trials: int = 20) -> Dict[str, Any]:
    """
    Optimise les hyperparam√®tres du mod√®le

    Args:
        symbol: Symbole pour l'optimisation
        max_trials: Nombre maximum d'essais

    Returns:
        Meilleurs hyperparam√®tres trouv√©s
    """
    try:
        logger.info(f"üîß Optimisation des hyperparam√®tres pour {symbol}")

        best_config = None
        best_score = 0.0
        optimization_results = []

        # D√©finir l'espace de recherche
        search_space = {
            'lstm_units': [
                [32, 16], [64, 32], [64, 32, 16], [128, 64, 32]
            ],
            'dense_units': [
                [16], [32, 16], [64, 32], [32, 16, 8]
            ],
            'dropout_rate': [0.1, 0.2, 0.3, 0.4],
            'learning_rate': [0.0001, 0.001, 0.01],
            'batch_size': [16, 32, 64]
        }

        # Recherche al√©atoire
        import random
        for trial in range(max_trials):
            logger.info(f"üìä Essai {trial + 1}/{max_trials}")

            # G√©n√©rer une configuration al√©atoire
            trial_config = ModelConfig(
                lstm_units=random.choice(search_space['lstm_units']),
                dense_units=random.choice(search_space['dense_units']),
                dropout_rate=random.choice(search_space['dropout_rate']),
                learning_rate=random.choice(search_space['learning_rate']),
                batch_size=random.choice(search_space['batch_size']),
                epochs=20  # Moins d'√©poques pour l'optimisation
            )

            try:
                # Entra√Æner avec cette configuration
                trainer = ModelTrainer(TrainingConfig(
                    symbol=symbol,
                    training_days=14,  # Moins de donn√©es pour √™tre plus rapide
                    epochs=20
                ))

                results = trainer.train_model(trial_config)
                score = results.best_metrics.accuracy

                optimization_results.append({
                    'trial': trial + 1,
                    'config': asdict(trial_config),
                    'score': score,
                    'metrics': asdict(results.best_metrics)
                })

                if score > best_score:
                    best_score = score
                    best_config = trial_config
                    logger.info(f"‚ú® Nouveau meilleur score: {score:.3f}")

            except Exception as e:
                logger.warning(f"Essai {trial + 1} √©chou√©: {e}")
                continue

        # R√©sultats de l'optimisation
        optimization_summary = {
            'best_config': asdict(best_config) if best_config else None,
            'best_score': best_score,
            'trials_completed': len(optimization_results),
            'optimization_results': optimization_results,
            'optimization_timestamp': datetime.now(timezone.utc).isoformat()
        }

        logger.info(f"üéØ Optimisation termin√©e - Meilleur score: {best_score:.3f}")
        return optimization_summary

    except Exception as e:
        logger.error(f"Erreur optimisation hyperparam√®tres: {e}")
        return {
            'error': str(e),
            'best_score': 0.0,
            'trials_completed': 0
        }


def predict_direction(symbol: str = "R_10", timeframe: str = "1m") -> Optional[str]:
    """
    Pr√©dit uniquement la direction du mouvement

    Args:
        symbol: Symbole √† pr√©dire
        timeframe: Timeframe des donn√©es

    Returns:
        Direction pr√©dite ('UP', 'DOWN', 'STABLE') ou None
    """
    try:
        result = model_predictor.predict(symbol, timeframe)
        return result.predicted_direction if result else None

    except Exception as e:
        logger.error(f"Erreur pr√©diction direction: {e}")
        return None


def batch_predict(symbols: List[str], timeframe: str = "1m") -> Dict[str, Optional[PredictionResult]]:
    """
    Pr√©dit pour plusieurs symboles en une fois

    Args:
        symbols: Liste des symboles
        timeframe: Timeframe des donn√©es

    Returns:
        Dictionnaire des pr√©dictions
    """
    return model_predictor.batch_predict(symbols, timeframe)


def get_model_performance() -> ModelPerformance:
    """
    Retourne la performance actuelle des mod√®les

    Returns:
        M√©triques de performance consolid√©es
    """
    try:
        # Performance du mod√®le actuel
        if model_predictor.model:
            model_perf = evaluate_model_performance(model_predictor.model)
        else:
            model_perf = ModelPerformance()

        # Ajouter les statistiques de pr√©diction
        pred_stats = model_predictor.get_prediction_stats()

        model_perf.total_predictions = pred_stats.get('total_predictions', 0)
        model_perf.successful_predictions = pred_stats.get('successful_predictions', 0)

        if model_perf.total_predictions > 0:
            model_perf.prediction_consistency = (
                    model_perf.successful_predictions / model_perf.total_predictions
            )

        return model_perf

    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration performance: {e}")
        return ModelPerformance()


def get_ai_pipeline_status() -> Dict[str, Any]:
    """
    Retourne le statut complet du pipeline IA

    Returns:
        Statut de tous les composants IA
    """
    try:
        status = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'overall_health': 'unknown',
            'components': {}
        }

        # Statut du mod√®le LSTM
        model_loaded = lstm_model.model is not None
        status['components']['lstm_model'] = {
            'loaded': model_loaded,
            'architecture': lstm_model.config.architecture.value if lstm_model else 'unknown',
            'info': lstm_model.get_model_info() if model_loaded else {}
        }

        # Statut de l'entra√Æneur
        trainer_stats = model_trainer.get_training_stats()
        status['components']['trainer'] = {
            'models_trained': trainer_stats.get('models_trained', 0),
            'last_training': trainer_stats.get('last_training_date'),
            'best_accuracy': trainer_stats.get('best_accuracy_achieved', 0.0)
        }

        # Statut du pr√©dicteur
        predictor_stats = model_predictor.get_prediction_stats()
        status['components']['predictor'] = {
            'model_loaded': predictor_stats.get('model_loaded', False),
            'total_predictions': predictor_stats.get('total_predictions', 0),
            'success_rate': predictor_stats.get('success_rate', 0.0),
            'avg_processing_time': predictor_stats.get('avg_processing_time_ms', 0.0)
        }

        # Sant√© globale
        health_factors = [
            model_loaded,
            trainer_stats.get('models_trained', 0) > 0,
            predictor_stats.get('success_rate', 0.0) > 0.7
        ]

        if all(health_factors):
            status['overall_health'] = 'excellent'
        elif any(health_factors):
            status['overall_health'] = 'partial'
        else:
            status['overall_health'] = 'critical'

        return status

    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration statut pipeline: {e}")
        return {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'overall_health': 'error',
            'error': str(e)
        }


def auto_retrain_model(symbol: str = "R_10",
                       performance_threshold: float = 0.05) -> Dict[str, Any]:
    """
    Red√©clenche automatiquement l'entra√Ænement si les performances d√©gradent

    Args:
        symbol: Symbole pour le r√©entra√Ænement
        performance_threshold: Seuil de d√©gradation pour d√©clencher le r√©entra√Ænement

    Returns:
        R√©sultats du r√©entra√Ænement
    """
    try:
        logger.info(f"üîÑ V√©rification de la n√©cessit√© de r√©entra√Æner pour {symbol}")

        # √âvaluer les performances actuelles
        current_performance = get_model_performance()

        # V√©rifier si un r√©entra√Ænement est n√©cessaire
        needs_retraining = False
        reasons = []

        # Performance d√©grad√©e
        if current_performance.accuracy < (current_performance.benchmark_accuracy + performance_threshold):
            needs_retraining = True
            reasons.append(f"Performance d√©grad√©e: {current_performance.accuracy:.3f}")

        # Mod√®le trop ancien
        if model_predictor.last_model_update:
            age_hours = (datetime.now(timezone.utc) - model_predictor.last_model_update).total_seconds() / 3600
            if age_hours > config.ai_model.model_retrain_frequency_hours:
                needs_retraining = True
                reasons.append(f"Mod√®le ancien: {age_hours:.1f} heures")

        # Taux d'√©chec trop √©lev√©
        pred_stats = model_predictor.get_prediction_stats()
        failure_rate = pred_stats.get('failure_rate', 0.0)
        if failure_rate > 0.2:  # Plus de 20% d'√©checs
            needs_retraining = True
            reasons.append(f"Taux d'√©chec √©lev√©: {failure_rate:.1%}")

        if not needs_retraining:
            return {
                'retraining_triggered': False,
                'reason': 'Performance satisfaisante',
                'current_accuracy': current_performance.accuracy,
                'timestamp': datetime.now(timezone.utc).isoformat()
            }

        logger.info(f"üöÄ R√©entra√Ænement n√©cessaire: {', '.join(reasons)}")

        # Lancer le r√©entra√Ænement
        retraining_results = train_and_evaluate_model(symbol=symbol)

        # Charger le nouveau mod√®le dans le pr√©dicteur
        if 'training_results' in retraining_results:
            model_path = retraining_results['training_results'].get('model_path')
            if model_path and os.path.exists(model_path):
                model_predictor.load_model(model_path)
                logger.info("‚úÖ Nouveau mod√®le charg√© dans le pr√©dicteur")

        return {
            'retraining_triggered': True,
            'reasons': reasons,
            'retraining_results': retraining_results,
            'new_performance': get_model_performance().to_dict(),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }

    except Exception as e:
        logger.error(f"Erreur r√©entra√Ænement automatique: {e}")
        return {
            'retraining_triggered': False,
            'error': str(e),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }


def load_best_model(models_dir: str = "models") -> bool:
    """
    Charge le meilleur mod√®le disponible

    Args:
        models_dir: Dossier contenant les mod√®les

    Returns:
        True si chargement r√©ussi
    """
    try:
        if not os.path.exists(models_dir):
            logger.warning(f"Dossier des mod√®les non trouv√©: {models_dir}")
            return False

        # Lister tous les fichiers d'historique (contiennent les m√©triques)
        history_files = [f for f in os.listdir(models_dir) if f.endswith('_history.json')]

        if not history_files:
            logger.warning("Aucun fichier d'historique trouv√©")
            return False

        best_model_path = None
        best_accuracy = 0.0

        # Parcourir tous les mod√®les pour trouver le meilleur
        for history_file in history_files:
            try:
                history_path = os.path.join(models_dir, history_file)

                with open(history_path, 'r') as f:
                    data = json.load(f)

                # R√©cup√©rer la pr√©cision
                training_results = data.get('training_results', {})
                best_metrics = training_results.get('best_metrics', {})
                accuracy = best_metrics.get('accuracy', 0.0)

                if accuracy > best_accuracy:
                    best_accuracy = accuracy
                    # Construire le chemin du mod√®le correspondant
                    model_filename = history_file.replace('_history.json', '.h5')
                    model_path = os.path.join(models_dir, model_filename)

                    if os.path.exists(model_path):
                        best_model_path = model_path

            except Exception as e:
                logger.warning(f"Erreur lecture de {history_file}: {e}")
                continue

        if best_model_path:
            success = model_predictor.load_model(best_model_path)
            if success:
                logger.info(f"‚úÖ Meilleur mod√®le charg√©: {best_model_path} (accuracy: {best_accuracy:.3f})")
            return success
        else:
            logger.warning("Aucun mod√®le valide trouv√©")
            return False

    except Exception as e:
        logger.error(f"Erreur chargement du meilleur mod√®le: {e}")
        return False


def get_ai_insights(symbol: str = "R_10", timeframe: str = "1m") -> AIInsights:
    """
    G√©n√®re des insights IA avanc√©s sur le march√©

    Args:
        symbol: Symbole √† analyser
        timeframe: Timeframe des donn√©es

    Returns:
        Insights g√©n√©r√©s par l'IA
    """
    try:
        insights = AIInsights()

        # Pr√©diction principale
        prediction = model_predictor.predict(symbol, timeframe)

        if prediction:
            insights.market_direction_confidence = prediction.confidence
            insights.trading_recommendation = prediction.predicted_direction

            # √âvaluation du risque bas√©e sur la confiance
            if prediction.confidence > 0.8:
                insights.risk_assessment = "LOW"
            elif prediction.confidence > 0.6:
                insights.risk_assessment = "MEDIUM"
            else:
                insights.risk_assessment = "HIGH"

            # Informations sur le mod√®le
            insights.model_versions_used = [prediction.model_version]

        # Pr√©diction de volatilit√© (bas√©e sur les patterns r√©cents)
        try:
            # R√©cup√©rer les donn√©es r√©centes pour analyser la volatilit√©
            end_time = datetime.now(timezone.utc)
            start_time = end_time - timedelta(hours=2)

            feature_set = prepare_training_data(
                symbol=symbol,
                timeframe=timeframe,
                start_date=start_time,
                end_date=end_time
            )

            if not feature_set.price_features.empty:
                # Calculer la volatilit√© r√©cente
                prices = feature_set.price_features.get('close', pd.Series())
                if len(prices) > 10:
                    returns = prices.pct_change().dropna()
                    volatility = returns.std()

                    if volatility > 0.01:  # Plus de 1%
                        insights.volatility_forecast = "HIGH"
                    elif volatility < 0.005:  # Moins de 0.5%
                        insights.volatility_forecast = "LOW"
                    else:
                        insights.volatility_forecast = "NORMAL"

                    # Force de tendance
                    if len(prices) > 20:
                        sma_short = prices.rolling(10).mean().iloc[-1]
                        sma_long = prices.rolling(20).mean().iloc[-1]
                        current_price = prices.iloc[-1]

                        trend_score = 0.0
                        if current_price > sma_short > sma_long:
                            trend_score = (current_price - sma_long) / sma_long
                        elif current_price < sma_short < sma_long:
                            trend_score = (sma_long - current_price) / sma_long

                        insights.trend_strength = min(1.0, abs(trend_score) * 100)

        except Exception as e:
            logger.warning(f"Erreur analyse de volatilit√©: {e}")

        # Timeframe optimal (bas√© sur la performance du mod√®le)
        performance = get_model_performance()
        if performance.accuracy > 0.7:
            insights.optimal_timeframe = timeframe
        else:
            # Sugg√©rer un timeframe diff√©rent si performance faible
            timeframe_alternatives = {"1m": "5m", "5m": "15m", "15m": "1h"}
            insights.optimal_timeframe = timeframe_alternatives.get(timeframe, timeframe)

        # Score de qualit√© des donn√©es
        pred_stats = model_predictor.get_prediction_stats()
        insights.data_quality_score = pred_stats.get('success_rate', 0.5)

        return insights

    except Exception as e:
        logger.error(f"Erreur g√©n√©ration insights IA: {e}")
        return AIInsights()


def validate_model_performance(min_accuracy: float = 0.55,
                               min_predictions: int = 100) -> Dict[str, Any]:
    """
    Valide que les performances du mod√®le respectent les crit√®res

    Args:
        min_accuracy: Pr√©cision minimale requise
        min_predictions: Nombre minimum de pr√©dictions pour valider

    Returns:
        R√©sultats de validation
    """
    try:
        performance = get_model_performance()
        pred_stats = model_predictor.get_prediction_stats()

        validation_results = {
            'validation_passed': True,
            'issues': [],
            'recommendations': [],
            'performance_metrics': performance.to_dict(),
            'validation_timestamp': datetime.now(timezone.utc).isoformat()
        }

        # V√©rifier la pr√©cision
        if performance.accuracy < min_accuracy:
            validation_results['validation_passed'] = False
            validation_results['issues'].append(
                f"Pr√©cision insuffisante: {performance.accuracy:.3f} < {min_accuracy:.3f}"
            )
            validation_results['recommendations'].append("R√©entra√Æner le mod√®le avec plus de donn√©es")

        # V√©rifier le nombre de pr√©dictions
        total_predictions = pred_stats.get('total_predictions', 0)
        if total_predictions < min_predictions:
            validation_results['validation_passed'] = False
            validation_results['issues'].append(
                f"Pas assez de pr√©dictions pour valider: {total_predictions} < {min_predictions}"
            )
            validation_results['recommendations'].append("Attendre plus de pr√©dictions avant validation")

        # V√©rifier le taux de succ√®s
        success_rate = pred_stats.get('success_rate', 0.0)
        if success_rate < 0.8:  # Moins de 80% de pr√©dictions r√©ussies
            validation_results['issues'].append(
                f"Taux de succ√®s faible: {success_rate:.1%}"
            )
            validation_results['recommendations'].append("V√©rifier la qualit√© des donn√©es d'entr√©e")

        # V√©rifier les temps de traitement
        avg_time = pred_stats.get('avg_processing_time_ms', 0.0)
        if avg_time > 500:  # Plus de 500ms en moyenne
            validation_results['issues'].append(
                f"Temps de traitement √©lev√©: {avg_time:.1f}ms"
            )
            validation_results['recommendations'].append("Optimiser l'architecture du mod√®le")

        # Recommandations g√©n√©rales
        if validation_results['validation_passed']:
            validation_results['recommendations'].append("Mod√®le valid√© - Performance satisfaisante")
        else:
            validation_results['recommendations'].append("Mod√®le n√©cessite une attention imm√©diate")

        return validation_results

    except Exception as e:
        logger.error(f"Erreur validation performance: {e}")
        return {
            'validation_passed': False,
            'error': str(e),
            'validation_timestamp': datetime.now(timezone.utc).isoformat()
        }


def print_ai_module_banner():
    """Affiche la banni√®re du module IA"""
    print("=" * 80)
    print("üß† TRADING BOT VOLATILITY 10 - MODULE D'INTELLIGENCE ARTIFICIELLE")
    print("=" * 80)
    print(f"üì¶ Version: {__version__}")
    print(f"üë• Auteur: {__author__}")
    print(f"üìù Description: {__description__}")

    # Statut du pipeline IA
    status = get_ai_pipeline_status()
    health_emoji = {
        "excellent": "‚úÖ",
        "partial": "‚ö†Ô∏è",
        "critical": "‚ùå",
        "error": "üí•",
        "unknown": "‚ùì"
    }

    print(
        f"\nüè• Sant√© du pipeline IA: {health_emoji.get(status['overall_health'], '‚ùì')} {status['overall_health'].upper()}")

    # Composants
    components = status.get('components', {})
    for component, info in components.items():
        if component == 'lstm_model':
            loaded = info.get('loaded', False)
            arch = info.get('architecture', 'unknown')
            print(f"   {'‚úÖ' if loaded else '‚ùå'} Mod√®le LSTM: {arch}")
        elif component == 'trainer':
            models_trained = info.get('models_trained', 0)
            print(f"   üìö Entra√Æneur: {models_trained} mod√®les entra√Æn√©s")
        elif component == 'predictor':
            model_loaded = info.get('model_loaded', False)
            success_rate = info.get('success_rate', 0.0)
            print(f"   {'‚úÖ' if model_loaded else '‚ùå'} Pr√©dicteur: {success_rate:.1%} succ√®s")

    # Performance
    performance = get_model_performance()
    print(f"\nüìä Performance:")
    print(f"   Pr√©cision: {performance.accuracy:.1%}")
    print(f"   Pr√©cision directionnelle: {performance.directional_accuracy:.1%}")
    print(f"   Pr√©dictions totales: {performance.total_predictions}")

    print("=" * 80)


# Initialisation automatique au chargement du module
try:
    logger.info(f"Module IA charg√© (version {__version__})")

    # V√©rifier que tous les sous-modules sont charg√©s
    components_loaded = [
        lstm_model is not None,
        model_trainer is not None,
        model_predictor is not None
    ]

    if all(components_loaded):
        logger.info("‚úÖ Tous les modules IA sont op√©rationnels")

        # Tentative de chargement automatique du meilleur mod√®le
        if model_predictor.config.auto_load_best_model:
            load_best_model()

    else:
        logger.warning("‚ö†Ô∏è Certains modules IA ne sont pas charg√©s")

except Exception as e:
    logger.error(f"‚ö†Ô∏è Erreur lors de l'initialisation du module IA: {e}")
    # Ne pas faire planter l'import, permettre l'utilisation partielle