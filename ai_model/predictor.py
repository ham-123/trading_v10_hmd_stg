"""
Pr√©dicteur temps r√©el utilisant les mod√®les LSTM entra√Æn√©s
Optimis√© pour les pr√©dictions haute fr√©quence sur Volatility 10
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import logging
import joblib
import os
import json
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, asdict
import warnings
from threading import Lock
import time

from config import config
from data import db_manager, prepare_training_data, FeatureSet
from .lstm_model import LSTMModel, ModelConfig, ModelMetrics, PredictionType
from .trainer import ModelTrainer

# Configuration du logger
logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore')


@dataclass
class PredictionResult:
    """R√©sultat d'une pr√©diction"""
    # Pr√©diction principale
    predicted_price: Optional[float] = None
    predicted_direction: Optional[str] = None  # 'UP', 'DOWN', 'STABLE'
    confidence: float = 0.0

    # Pr√©dictions d√©taill√©es
    direction_probabilities: Optional[Dict[str, float]] = None  # {'DOWN': 0.2, 'STABLE': 0.3, 'UP': 0.5}
    price_change_pct: Optional[float] = None
    volatility_prediction: Optional[float] = None

    # Contexte
    current_price: float = 0.0
    prediction_horizon: int = 5  # minutes
    timestamp: datetime = None

    # Qualit√© de la pr√©diction
    model_confidence: float = 0.0
    feature_quality_score: float = 0.0
    prediction_reliability: str = "UNKNOWN"  # LOW, MEDIUM, HIGH

    # M√©tadonn√©es
    model_version: str = ""
    features_used: List[str] = None
    processing_time_ms: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            'predicted_price': self.predicted_price,
            'predicted_direction': self.predicted_direction,
            'confidence': self.confidence,
            'direction_probabilities': self.direction_probabilities,
            'price_change_pct': self.price_change_pct,
            'volatility_prediction': self.volatility_prediction,
            'current_price': self.current_price,
            'prediction_horizon': self.prediction_horizon,
            'timestamp': self.timestamp.isoformat() if self.timestamp else None,
            'model_confidence': self.model_confidence,
            'feature_quality_score': self.feature_quality_score,
            'prediction_reliability': self.prediction_reliability,
            'model_version': self.model_version,
            'features_used': self.features_used or [],
            'processing_time_ms': self.processing_time_ms
        }


@dataclass
class PredictionConfig:
    """Configuration pour les pr√©dictions"""
    # Mod√®le
    model_path: Optional[str] = None
    auto_load_best_model: bool = True
    model_update_frequency_hours: int = 24

    # Donn√©es
    feature_update_frequency_seconds: int = 60
    min_data_quality_score: float = 0.7
    max_data_age_minutes: int = 5

    # Pr√©dictions
    prediction_cache_size: int = 1000
    cache_timeout_seconds: int = 30
    batch_prediction_size: int = 50

    # Qualit√©
    min_confidence_threshold: float = 0.6
    min_reliability_threshold: str = "MEDIUM"
    enable_prediction_validation: bool = True

    # Performance
    max_prediction_time_ms: float = 100.0
    enable_performance_monitoring: bool = True


class ModelPredictor:
    """Pr√©dicteur utilisant les mod√®les LSTM pour les pr√©dictions temps r√©el"""

    def __init__(self, config: PredictionConfig = None):
        self.config = config or PredictionConfig()

        # Mod√®le et √©tat
        self.model = None
        self.model_info = {}
        self.last_model_update = None
        self.model_lock = Lock()

        # Cache des pr√©dictions
        self.prediction_cache = {}
        self.feature_cache = {}
        self.last_feature_update = None

        # Statistiques
        self.prediction_stats = {
            'total_predictions': 0,
            'successful_predictions': 0,
            'failed_predictions': 0,
            'avg_processing_time_ms': 0.0,
            'avg_confidence': 0.0,
            'cache_hits': 0,
            'cache_misses': 0,
            'last_prediction_time': None,
            'model_loads': 0,
            'feature_updates': 0
        }

        # Historique des pr√©dictions
        self.prediction_history = []
        self.max_history_size = 10000

        # Auto-chargement du mod√®le
        if self.config.auto_load_best_model:
            self._auto_load_best_model()

        logger.info("Pr√©dicteur LSTM initialis√©")

    def _auto_load_best_model(self) -> bool:
        """Charge automatiquement le meilleur mod√®le disponible"""
        try:
            if self.config.model_path and os.path.exists(self.config.model_path):
                return self.load_model(self.config.model_path)

            # Chercher le meilleur mod√®le dans le dossier des mod√®les
            models_dir = "models"
            if not os.path.exists(models_dir):
                logger.warning("Dossier des mod√®les non trouv√©")
                return False

            # Lister tous les mod√®les .h5
            model_files = [f for f in os.listdir(models_dir) if f.endswith('.h5')]

            if not model_files:
                logger.warning("Aucun mod√®le trouv√©")
                return False

            # Trier par date de modification (le plus r√©cent en premier)
            model_files.sort(key=lambda f: os.path.getmtime(os.path.join(models_dir, f)), reverse=True)

            # Charger le mod√®le le plus r√©cent
            best_model_path = os.path.join(models_dir, model_files[0])
            logger.info(f"Chargement automatique du mod√®le: {best_model_path}")

            return self.load_model(best_model_path)

        except Exception as e:
            logger.error(f"Erreur lors du chargement automatique: {e}")
            return False

    def load_model(self, model_path: str) -> bool:
        """
        Charge un mod√®le LSTM

        Args:
            model_path: Chemin vers le mod√®le

        Returns:
            True si chargement r√©ussi
        """
        try:
            with self.model_lock:
                logger.info(f"üì• Chargement du mod√®le: {model_path}")

                if not os.path.exists(model_path):
                    logger.error(f"Mod√®le non trouv√©: {model_path}")
                    return False

                # Charger le mod√®le Keras
                keras_model = keras.models.load_model(model_path)

                # Cr√©er l'objet LSTMModel
                self.model = LSTMModel()
                self.model.model = keras_model

                # Charger les m√©tadonn√©es
                self._load_model_metadata(model_path)

                # Mettre √† jour les statistiques
                self.last_model_update = datetime.now(timezone.utc)
                self.prediction_stats['model_loads'] += 1

                logger.info(f"‚úÖ Mod√®le charg√© avec succ√®s")
                return True

        except Exception as e:
            logger.error(f"Erreur chargement du mod√®le: {e}")
            return False

    def _load_model_metadata(self, model_path: str):
        """Charge les m√©tadonn√©es du mod√®le"""
        try:
            # Chercher le fichier d'historique correspondant
            history_path = model_path.replace('.h5', '_history.json')

            if os.path.exists(history_path):
                with open(history_path, 'r') as f:
                    data = json.load(f)

                    if 'model_config' in data:
                        self.model_info.update(data['model_config'])

                    if 'training_results' in data:
                        training_results = data['training_results']
                        self.model_info['last_accuracy'] = training_results.get('best_metrics', {}).get('accuracy', 0.0)
                        self.model_info['last_training_time'] = training_results.get('training_time', 0.0)

            # Informations basiques du mod√®le
            if self.model and self.model.model:
                self.model_info['input_shape'] = self.model.model.input_shape
                self.model_info['output_shape'] = self.model.model.output_shape
                self.model_info['parameters'] = self.model.model.count_params()

            logger.debug(f"M√©tadonn√©es du mod√®le charg√©es: {len(self.model_info)} √©l√©ments")

        except Exception as e:
            logger.warning(f"Impossible de charger les m√©tadonn√©es: {e}")

    def predict(self, symbol: str = "R_10", timeframe: str = "1m",
                force_refresh: bool = False) -> Optional[PredictionResult]:
        """
        Effectue une pr√©diction pour un symbole

        Args:
            symbol: Symbole √† pr√©dire
            timeframe: Timeframe des donn√©es
            force_refresh: Forcer le rafra√Æchissement du cache

        Returns:
            R√©sultat de pr√©diction ou None si √©chec
        """
        start_time = time.time()

        try:
            # V√©rifier si le mod√®le est charg√©
            if self.model is None or self.model.model is None:
                logger.warning("Aucun mod√®le charg√© pour les pr√©dictions")
                self._auto_load_best_model()

                if self.model is None:
                    self.prediction_stats['failed_predictions'] += 1
                    return None

            # V√©rifier le cache
            cache_key = f"{symbol}_{timeframe}"
            current_time = datetime.now(timezone.utc)

            if not force_refresh and cache_key in self.prediction_cache:
                cached_result, cache_time = self.prediction_cache[cache_key]
                if (current_time - cache_time).total_seconds() < self.config.cache_timeout_seconds:
                    self.prediction_stats['cache_hits'] += 1
                    return cached_result

            self.prediction_stats['cache_misses'] += 1

            # R√©cup√©rer et pr√©parer les features
            features = self._get_prediction_features(symbol, timeframe)
            if features is None:
                logger.warning("Impossible de r√©cup√©rer les features pour la pr√©diction")
                self.prediction_stats['failed_predictions'] += 1
                return None

            # Effectuer la pr√©diction
            with self.model_lock:
                prediction_result = self._make_prediction(features, symbol)

            if prediction_result is None:
                self.prediction_stats['failed_predictions'] += 1
                return None

            # Calculer le temps de traitement
            processing_time = (time.time() - start_time) * 1000
            prediction_result.processing_time_ms = processing_time

            # Valider la pr√©diction
            if self.config.enable_prediction_validation:
                prediction_result = self._validate_prediction(prediction_result)

            # Mettre en cache
            self.prediction_cache[cache_key] = (prediction_result, current_time)

            # Nettoyer le cache si n√©cessaire
            if len(self.prediction_cache) > self.config.prediction_cache_size:
                self._cleanup_cache()

            # Ajouter √† l'historique
            self._add_to_history(prediction_result)

            # Mettre √† jour les statistiques
            self._update_prediction_stats(prediction_result, processing_time)

            logger.debug(f"Pr√©diction effectu√©e en {processing_time:.1f}ms")
            return prediction_result

        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction: {e}")
            self.prediction_stats['failed_predictions'] += 1
            return None

    def _get_prediction_features(self, symbol: str, timeframe: str) -> Optional[np.ndarray]:
        """R√©cup√®re et pr√©pare les features pour la pr√©diction"""
        try:
            # V√©rifier le cache des features
            cache_key = f"features_{symbol}_{timeframe}"
            current_time = datetime.now(timezone.utc)

            if (cache_key in self.feature_cache and
                    self.last_feature_update and
                    (
                            current_time - self.last_feature_update).total_seconds() < self.config.feature_update_frequency_seconds):
                return self.feature_cache[cache_key]

            # R√©cup√©rer les donn√©es r√©centes
            end_time = current_time
            start_time = end_time - timedelta(hours=2)  # 2 heures de donn√©es

            feature_set = prepare_training_data(
                symbol=symbol,
                timeframe=timeframe,
                start_date=start_time,
                end_date=end_time
            )

            if feature_set.price_features.empty:
                logger.warning("Aucune donn√©e r√©cente disponible")
                return None

            # Pr√©parer les s√©quences
            X, _ = self.model.prepare_sequences(feature_set)

            if len(X) == 0:
                logger.warning("Impossible de cr√©er des s√©quences de pr√©diction")
                return None

            # Prendre la derni√®re s√©quence pour la pr√©diction
            prediction_sequence = X[-1:]  # Garder la dimension batch

            # Mettre en cache
            self.feature_cache[cache_key] = prediction_sequence
            self.last_feature_update = current_time
            self.prediction_stats['feature_updates'] += 1

            return prediction_sequence

        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration des features: {e}")
            return None

    def _make_prediction(self, features: np.ndarray, symbol: str) -> Optional[PredictionResult]:
        """Effectue la pr√©diction avec le mod√®le"""
        try:
            # Pr√©diction avec le mod√®le
            raw_prediction = self.model.model.predict(features, verbose=0)

            # R√©cup√©rer le prix actuel
            current_price = self._get_current_price(symbol)
            if current_price is None:
                logger.warning("Impossible de r√©cup√©rer le prix actuel")
                current_price = 0.0

            # Traiter selon le type de pr√©diction
            result = PredictionResult(
                current_price=current_price,
                timestamp=datetime.now(timezone.utc),
                model_version=self.model_info.get('version', 'unknown'),
                features_used=self.model.feature_names[:10] if self.model.feature_names else [],
                prediction_horizon=self.model.config.prediction_horizon if self.model else 5
            )

            if isinstance(raw_prediction, list):
                # Multi-output: [prix, direction, confiance]
                if len(raw_prediction) >= 3:
                    price_pred = raw_prediction[0][0, 0] if raw_prediction[0].size > 0 else current_price
                    direction_probs = raw_prediction[1][0] if raw_prediction[1].size > 0 else [0.33, 0.34, 0.33]
                    confidence_pred = raw_prediction[2][0, 0] if raw_prediction[2].size > 0 else 0.5

                    result.predicted_price = float(price_pred)
                    result.model_confidence = float(confidence_pred)

                    # Traiter les probabilit√©s de direction
                    direction_labels = ['DOWN', 'STABLE', 'UP']
                    result.direction_probabilities = {
                        direction_labels[i]: float(prob) for i, prob in enumerate(direction_probs)
                    }

                    # D√©terminer la direction pr√©dite
                    max_prob_idx = np.argmax(direction_probs)
                    result.predicted_direction = direction_labels[max_prob_idx]
                    result.confidence = float(direction_probs[max_prob_idx])

                    # Calculer le changement de prix pr√©dit
                    if current_price > 0:
                        result.price_change_pct = ((result.predicted_price - current_price) / current_price) * 100

            else:
                # Single output
                if len(raw_prediction.shape) > 1 and raw_prediction.shape[1] > 1:
                    # Classification de direction
                    direction_probs = raw_prediction[0]
                    direction_labels = ['DOWN', 'STABLE', 'UP']

                    result.direction_probabilities = {
                        direction_labels[i]: float(prob) for i, prob in enumerate(direction_probs)
                    }

                    max_prob_idx = np.argmax(direction_probs)
                    result.predicted_direction = direction_labels[max_prob_idx]
                    result.confidence = float(direction_probs[max_prob_idx])
                    result.model_confidence = result.confidence

                else:
                    # Pr√©diction de prix
                    predicted_price = float(raw_prediction[0, 0])
                    result.predicted_price = predicted_price

                    if current_price > 0:
                        price_change = ((predicted_price - current_price) / current_price) * 100
                        result.price_change_pct = price_change

                        # D√©terminer la direction bas√©e sur le changement de prix
                        if price_change > 0.1:
                            result.predicted_direction = 'UP'
                            result.confidence = min(0.9, abs(price_change) / 10)
                        elif price_change < -0.1:
                            result.predicted_direction = 'DOWN'
                            result.confidence = min(0.9, abs(price_change) / 10)
                        else:
                            result.predicted_direction = 'STABLE'
                            result.confidence = 0.6

                        result.model_confidence = result.confidence

            # Calculer la fiabilit√© de la pr√©diction
            result.prediction_reliability = self._calculate_reliability(result)

            return result

        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction: {e}")
            return None

    def _get_current_price(self, symbol: str) -> Optional[float]:
        """R√©cup√®re le prix actuel d'un symbole"""
        try:
            latest_price = db_manager.get_latest_price(symbol, "1m")
            if latest_price:
                return latest_price.close_price
            return None
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration prix actuel: {e}")
            return None

    def _calculate_reliability(self, result: PredictionResult) -> str:
        """Calcule la fiabilit√© de la pr√©diction"""
        try:
            # Facteurs de fiabilit√©
            confidence_score = result.confidence
            model_confidence_score = result.model_confidence

            # Score bas√© sur l'historique du mod√®le
            model_accuracy = self.model_info.get('last_accuracy', 0.5)

            # Score combin√©
            reliability_score = (confidence_score * 0.4 +
                                 model_confidence_score * 0.3 +
                                 model_accuracy * 0.3)

            if reliability_score >= 0.8:
                return "HIGH"
            elif reliability_score >= 0.6:
                return "MEDIUM"
            else:
                return "LOW"

        except Exception as e:
            logger.error(f"Erreur calcul de fiabilit√©: {e}")
            return "UNKNOWN"

    def _validate_prediction(self, result: PredictionResult) -> PredictionResult:
        """Valide et ajuste la pr√©diction si n√©cessaire"""
        try:
            # V√©rifier les seuils de confiance
            if result.confidence < self.config.min_confidence_threshold:
                result.prediction_reliability = "LOW"
                logger.debug(f"Pr√©diction de faible confiance: {result.confidence:.3f}")

            # V√©rifier la coh√©rence des pr√©dictions de prix et de direction
            if result.predicted_price and result.price_change_pct:
                predicted_direction_from_price = 'UP' if result.price_change_pct > 0.1 else (
                    'DOWN' if result.price_change_pct < -0.1 else 'STABLE')

                if result.predicted_direction != predicted_direction_from_price:
                    logger.debug("Incoh√©rence entre pr√©diction de prix et de direction")
                    # R√©duire la confiance en cas d'incoh√©rence
                    result.confidence *= 0.8
                    result.prediction_reliability = "LOW"

            # V√©rifier les limites de prix (pour Volatility 10, changements extr√™mes improbables)
            if result.price_change_pct and abs(result.price_change_pct) > 5.0:  # Plus de 5% de changement
                logger.warning(f"Pr√©diction de changement de prix extr√™me: {result.price_change_pct:.2f}%")
                result.confidence *= 0.5
                result.prediction_reliability = "LOW"

            return result

        except Exception as e:
            logger.error(f"Erreur validation de pr√©diction: {e}")
            return result

    def _cleanup_cache(self):
        """Nettoie les anciens √©l√©ments du cache"""
        try:
            # Garder seulement les √©l√©ments les plus r√©cents
            if len(self.prediction_cache) > self.config.prediction_cache_size:
                sorted_items = sorted(
                    self.prediction_cache.items(),
                    key=lambda x: x[1][1],  # Trier par timestamp
                    reverse=True
                )

                # Garder seulement les plus r√©cents
                keep_items = sorted_items[:self.config.prediction_cache_size // 2]
                self.prediction_cache = dict(keep_items)

                logger.debug(f"Cache nettoy√©: {len(keep_items)} √©l√©ments conserv√©s")

        except Exception as e:
            logger.error(f"Erreur nettoyage du cache: {e}")

    def _add_to_history(self, result: PredictionResult):
        """Ajoute une pr√©diction √† l'historique"""
        try:
            self.prediction_history.append(result)

            # Limiter la taille de l'historique
            if len(self.prediction_history) > self.max_history_size:
                self.prediction_history = self.prediction_history[-self.max_history_size // 2:]

        except Exception as e:
            logger.error(f"Erreur ajout √† l'historique: {e}")

    def _update_prediction_stats(self, result: PredictionResult, processing_time: float):
        """Met √† jour les statistiques de pr√©diction"""
        try:
            self.prediction_stats['total_predictions'] += 1
            self.prediction_stats['successful_predictions'] += 1
            self.prediction_stats['last_prediction_time'] = result.timestamp

            # Temps de traitement moyen
            total_predictions = self.prediction_stats['total_predictions']
            old_avg = self.prediction_stats['avg_processing_time_ms']
            self.prediction_stats['avg_processing_time_ms'] = (
                    (old_avg * (total_predictions - 1) + processing_time) / total_predictions
            )

            # Confiance moyenne
            old_avg_conf = self.prediction_stats['avg_confidence']
            self.prediction_stats['avg_confidence'] = (
                    (old_avg_conf * (total_predictions - 1) + result.confidence) / total_predictions
            )

        except Exception as e:
            logger.error(f"Erreur mise √† jour des statistiques: {e}")

    def batch_predict(self, symbols: List[str], timeframe: str = "1m") -> Dict[str, Optional[PredictionResult]]:
        """
        Effectue des pr√©dictions en lot pour plusieurs symboles

        Args:
            symbols: Liste des symboles
            timeframe: Timeframe des donn√©es

        Returns:
            Dictionnaire des pr√©dictions par symbole
        """
        try:
            logger.info(f"Pr√©dictions en lot pour {len(symbols)} symboles")

            results = {}

            for symbol in symbols:
                try:
                    result = self.predict(symbol, timeframe)
                    results[symbol] = result
                except Exception as e:
                    logger.error(f"Erreur pr√©diction pour {symbol}: {e}")
                    results[symbol] = None

            successful_predictions = sum(1 for r in results.values() if r is not None)
            logger.info(f"Pr√©dictions en lot termin√©es: {successful_predictions}/{len(symbols)} r√©ussies")

            return results

        except Exception as e:
            logger.error(f"Erreur pr√©dictions en lot: {e}")
            return {}

    def get_prediction_confidence_distribution(self, hours: int = 24) -> Dict[str, int]:
        """Retourne la distribution des niveaux de confiance sur une p√©riode"""
        try:
            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours)

            recent_predictions = [
                p for p in self.prediction_history
                if p.timestamp and p.timestamp > cutoff_time
            ]

            distribution = {"HIGH": 0, "MEDIUM": 0, "LOW": 0, "UNKNOWN": 0}

            for prediction in recent_predictions:
                reliability = prediction.prediction_reliability
                if reliability in distribution:
                    distribution[reliability] += 1
                else:
                    distribution["UNKNOWN"] += 1

            return distribution

        except Exception as e:
            logger.error(f"Erreur calcul distribution de confiance: {e}")
            return {"HIGH": 0, "MEDIUM": 0, "LOW": 0, "UNKNOWN": 0}

    def get_prediction_accuracy(self, hours: int = 24) -> Dict[str, float]:
        """
        Calcule la pr√©cision des pr√©dictions r√©centes (n√©cessite des donn√©es de validation)

        Args:
            hours: Nombre d'heures √† analyser

        Returns:
            Dictionnaire avec les m√©triques de pr√©cision
        """
        try:
            # TODO: Impl√©menter la validation des pr√©dictions avec les donn√©es r√©elles
            # Cela n√©cessiterait de stocker les pr√©dictions et de les comparer avec les prix r√©els

            return {
                'directional_accuracy': 0.0,
                'price_accuracy_mae': 0.0,
                'confidence_accuracy': 0.0,
                'predictions_validated': 0
            }

        except Exception as e:
            logger.error(f"Erreur calcul de pr√©cision: {e}")
            return {'error': str(e)}

    def get_prediction_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de pr√©diction"""
        stats = self.prediction_stats.copy()

        # Ajouter des informations suppl√©mentaires
        stats['model_loaded'] = self.model is not None
        stats['model_info'] = self.model_info.copy()
        stats['cache_size'] = len(self.prediction_cache)
        stats['history_size'] = len(self.prediction_history)
        stats['last_model_update'] = self.last_model_update.isoformat() if self.last_model_update else None

        # Calculer le taux de r√©ussite
        total = stats['total_predictions']
        if total > 0:
            stats['success_rate'] = stats['successful_predictions'] / total
            stats['failure_rate'] = stats['failed_predictions'] / total
            stats['cache_hit_rate'] = stats['cache_hits'] / (stats['cache_hits'] + stats['cache_misses'])

        return stats


# Instance globale
model_predictor = ModelPredictor()


# Fonctions utilitaires
def predict_price(symbol: str = "R_10", timeframe: str = "1m") -> Optional[PredictionResult]:
    """Fonction utilitaire pour pr√©dire le prix d'un symbole"""
    return model_predictor.predict(symbol, timeframe)


def get_prediction_stats() -> Dict[str, Any]:
    """Fonction utilitaire pour r√©cup√©rer les statistiques de pr√©diction"""
    return model_predictor.get_prediction_stats()


if __name__ == "__main__":
    # Test du pr√©dicteur
    print("üîÆ Test du pr√©dicteur LSTM...")

    try:
        # Configuration de test
        test_config = PredictionConfig(
            auto_load_best_model=True,
            min_confidence_threshold=0.3,  # Seuil bas pour les tests
            cache_timeout_seconds=10
        )

        predictor = ModelPredictor(test_config)

        print(f"‚úÖ Pr√©dicteur configur√©")
        print(f"   Mod√®le charg√©: {predictor.model is not None}")
        print(f"   Auto-chargement: {test_config.auto_load_best_model}")

        # Test de pr√©diction (si mod√®le disponible)
        if predictor.model:
            try:
                result = predictor.predict("R_10", "1m")
                if result:
                    print(f"\nüîÆ Pr√©diction de test:")
                    print(
                        f"   Prix pr√©dit: {result.predicted_price:.5f}" if result.predicted_price else "   Prix pr√©dit: N/A")
                    print(f"   Direction: {result.predicted_direction}")
                    print(f"   Confiance: {result.confidence:.3f}")
                    print(f"   Fiabilit√©: {result.prediction_reliability}")
                    print(f"   Temps de traitement: {result.processing_time_ms:.1f}ms")
                else:
                    print(f"‚ùå Pr√©diction √©chou√©e")
            except Exception as e:
                print(f"‚ö†Ô∏è Test de pr√©diction √©chou√© (normal si pas de donn√©es): {e}")
        else:
            print(f"‚ö†Ô∏è Aucun mod√®le charg√© - test de pr√©diction ignor√©")

        # Test de pr√©dictions en lot
        try:
            batch_results = predictor.batch_predict(["R_10"])
            print(f"\nüìä Pr√©dictions en lot: {len(batch_results)} r√©sultats")
        except Exception as e:
            print(f"‚ö†Ô∏è Test batch √©chou√©: {e}")

        # Statistiques
        stats = predictor.get_prediction_stats()
        print(f"\nüìà Statistiques:")
        for key, value in list(stats.items())[:8]:  # Afficher les 8 premi√®res
            print(f"   {key}: {value}")

        print("‚úÖ Test du pr√©dicteur r√©ussi !")

    except Exception as e:
        print(f"‚ùå Erreur lors du test: {e}")
        logger.error(f"Test du pr√©dicteur √©chou√©: {e}")